# 分布式

## 分布式系统
#### 一.Quorum机制（保证分布式数据的更新/读取成功）
- 数据一致性：
  - 强一致性：在任意时刻，从任意不同副本取出的值都是一样的。
  - 弱一致性：有时泛指最终一致性，是指在任意时刻，可能由于网络延迟或者设备异常等原因，不同副本中的值可能会不一样，但经过一段时间后，最终会变成一样。
        显然，我们更想要做到强一致性的这种效果，那么有哪些方式可以实现呢，其中最为简单直接的就是WARO，也就是Write All Read one。
        
  - WARO协议:
  
      是一种简单的副本控制协议，当 Client 请求向某副本写数据时（更新数据），只有当所有的副本都更新成功之后，这次写操作才算成功，否则视为失败。这样的话，只需要读任何一个副本上的数据即可。但是WARO带来的影响是写服务的可用性较低，因为只要有一个副本更新失败，此次写操作就视为失败了。  
      到这里，再来看Quorum机制到底是个什么鬼？他比WARO又好在什么地方

- Quorum机制     
    Write + Read > N 存储副本W个成功即为成功，读取R个副本 R个副本和W个副本必有重叠，则通过版本号确定最新成功提交的版本号。
    
- quorum是一个机制，不是一个算法，Paxos、raft、zab都是quorum机制

- 使用这个设计：zookeeper选举， hadoop hdfs redis sentinel 

#### Raft
  - CAP理论： 分区容错性，一致性，可用性，不能同时保证。
    - Consistency（一致性）
      a存储后 b c d 都能立刻查到，查不到则不可用
    - Availability（可用性）
      客户端的请求都会保证响应
      必须保证可用，数据可以不完全一致
    - Partition tolerance（分区容忍性）
      - 脑裂
        主从切换过程中，原主库恢复可写，新主库也可写
      - 奇数个节点 raft算法 防止脑裂 
      - 基于raft算法 提交日志，半数以上收到日志可写入，切换主从后，要处理上一任的未提交的日志
      [防止脑裂](https://www.zhihu.com/search?type=content&q=redis%E8%84%91%E8%A3%82):
      min-slaves-to-write：与主节点通信的从节点数量必须大于等于该值主节点，否则主节点拒绝写入。
      min-slaves-max-lag：主节点与从节点通信的ACK消息延迟必须小于该值，否则主节点拒绝写入。 
      系统内网络问题导致多个分区产生，可能发生脑裂： 
      ：由于分布式系统通过网络进行通信，网络是不可靠的。当任意数量的消息丢失或延迟到达时，
      系统仍会继续提供服务，不会挂掉。换句话说，分区容忍性是站在分布式系统的角度，
      对访问本系统的客户端的再一种承诺：我会一直运行，不管我的内部出现何种数据同步问题，强调的是不挂掉。

  - Raft: 强一致性： quorum
    - 领导选举
    - 日志复制
    - 数据安全 

## 分布式存储

#### 分布式锁
   - [分布式锁](https://blog.csdn.net/xiaoxiaole0313/article/details/107011095/)
   - redis setNx 
     - 如果没释放，需要等过期
     - 可能过期了还没操作完，锁被别人抢到
     - value要具有唯一性  为了在解锁的时候，需要验证value是和加锁的一致才删除key。
     - 分布式
       - 单机
       - master - slave + sentinel
         - 切换主机 可能会丢失
       - cluster
         redlock quorum 机制
       - redisson 监听进程/线程 续期
   - etcd/zk
     - etcd 是基于 Raft 共识算法实现的， 一个写请求需要经过集群多数节点确认
     - 比如你可以通过 client 是否成功创建一个固 定的 key，来判断此 client 是否获得锁，
     你也可以通过多个 client 创建 prefix 相同，名称 不一样的 key，哪个 key 的 revision 最小，最终就是它获得锁。至于谁优谁劣，我作为思 考题的一部分，留给大家一起讨论。
     - Lease 与锁的活性
     `正如在06租约特性中和你介绍的，Lease 就是一种活性检测机制，它提供了检测各个客 户端存活的能力。你的业务 client 需定期向 etcd 服务发送"特殊心跳"汇报健康状态，若你
      未正常发送心跳，并超过和 etcd 服务约定的最大存活时间后，就会被 etcd 服务移除此 Lease 和其关联的数据。
      通过 Lease 机制就优雅地解决了 client 出现 crash 故障、client 与 etcd 集群网络出现隔 离等各类故障场景下的死锁问题。
      一旦超过 Lease TTL，它就能自动被释放，确保了其他 client 在 TTL 过期后能正常申请锁，保障了业务的可用性。`
     - Watch 与锁的可用性
       `当一个持有锁的 client crash 故障后，其他 client 如何快速感知到此锁失效了，快速获得
       锁呢，最大程度降低锁的不可用时间呢?
       答案是 Watch 特性。正如在 08 Watch 特性中和你介绍的，Watch 提供了高效的数据监 听能力。当其他 client 收到 Watch Delete 事件后，就可快速判断自己是否有资格获得 锁，极大减少了锁的不可用时间。
       ` 

#### 微服务
[微服务架构设计](https://www.cnblogs.com/wintersun/p/6219259.html)
[如何设计高可用的微服务架构](https://zhuanlan.zhihu.com/p/59265085)


#### 微服务数据一致性
[微服务下数据一致性](https://www.cnblogs.com/mahatmasmile/p/8530077.html)
[TCC Try cancel commit](https://www.cnblogs.com/jajian/p/10014145.html)
