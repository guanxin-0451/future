
## MYSQL
         
### 插件式存储引擎
   - InnoDB
     - mysql默认的事务型存储引擎(OLAP)
     - MVCC支持高并发
     - 四个标准隔离级别(未提交读、提交读、可重复读、可串行化)。
         `其默认级别时可重复读（REPEATABLE READ），在可重复读级别下，通过 MVCC + Next-Key Locking 防止幻读。`
     - 主索引是聚簇索引 索引中保存了数据，避免直接读盘。
     - 插入缓冲 二次写 紫石英哈希索引 预读
     - 优化 从磁盘读取数据时采用的可预测性读，能够自动在内存中创建 hash 索引以加速读操作的自适应哈希索引，以及能够加速插入操作的插入缓冲区等。
     - 在线热备份: MySQL 其他的存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合的场景中，停止写入可能也意味着停止读取。
   - MyISAM
     - 索引 B+tree 主索引：非聚簇索引（因为数据紧密格式存储）
     `设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。
      
      提供了大量的特性，包括压缩表、空间数据索引等。
      
      不支持事务。
      
      不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。
      
      可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。
      
      如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。`
   - InnoDB 和 MyISAM 的比较
        - 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
   
        - 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
   
        - 外键：InnoDB 支持外键。
   
        - 备份：InnoDB 支持在线热备份。
   
        - 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
   
        - 其它特性：MyISAM 支持压缩表和空间数据索引。
    - NDB集群存储引擎 share notion过架构的集群 数据全放在内存，非索引可以放在次盘。 join实在数据库层完成的，查询速度慢
    - Memory 存在内存里
    
### InnoDB体系结构
    ![innodb存储引擎体系架构](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633269283438.png)
    - 维护所有进程/线程需要访问的多个内部数据结构
    - 缓存磁盘上的数据，方便快速读取。数据修改之前先缓存
    - 重做日志。
    
  - 后台线程
    1. Master Thread
        
        `主要负责缓冲池的数据异步刷新到磁盘，保证数据一致性，脏页的刷新，合并插入缓冲，undo页的回收等`
    
    2. IO thread 
        `异步io，async`
    3. Purege Thread 
        `回收已经使用并分配的undo页`
    4.Page Cleaner Thread
        `脏页刷到文件中`
    
  - 内存
    - 缓冲池
      - 读取: 首先将磁盘读取到的页放在缓存池中，再次读取时，如果该页在缓存池中，则命中，读取。
      - 修改: 首先修改缓冲池的页，再以一定的频率刷到磁盘上。（通过checkpoint刷到磁盘）
      - 缓存的数据页类型: 索引页， 数据页，undo页，插入缓冲，紫石英哈希索引，锁，等。
        ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633271465564.png)
    - LRU List, Free List, Flush List
      - LRU List
        `innodb 加入了midpoint 新读到的页驾到LRU的中间点位置
        配置innodb_old_blocks_time，表示读到mid位置后需要等待多久才会被加入到LRU顶端
        `
      - Free List 空闲的缓存页链表
      - Flush List 缓冲池的页和磁盘上的页的数据不一致，通过checkpoint机制 将脏页刷新回磁盘。
  
  - checkpoint
    
  - [BufferPool](https://mp.weixin.qq.com/s/4ZZ_xWI-oPX735cMF_UBMw)

    
    
    
### 索引
   - B+ Tree 原理
     - 平衡树 + 顺序查找
     - 内部节点（索引节点）和叶子结点 叶子节点存数据
     - 节点的key 左子树都小于他 右子树都大于他
     - 查找
     
     `查找以典型的方式进行，类似于二叉查找树。起始于根节点，自顶向下遍历树，选择其分离值在要查找值的任意一边的子指针。在节点内部典型的使用是二分查找来确定这个位置。`
     - 插入：必须保证插入后叶子结点的记录依然有序
     ![插入的三种情况](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632734966459.png)
        1. 叶子结点没满 直接插入叶子结点
        2. 叶子结点满了 索引节点没满 拆分叶子page 拆成凉快
        3. 叶子结点和索引节点都满了: 拆分叶子结点的page 再拆分索引节点的page
        4. 旋转 leaf page已满 但是左右兄弟没满，会记录转移到兄弟节点上，左兄弟会用来做旋转
     - 删除: 保证删除后有序 填充因子（最小50%）
        ![删除的三种情况](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632736824521.png)
     - 特点：
        1. 磁盘io低，非叶子节点只存放索引，一次性读入内存的需要查找的关键字多。
        2. 查询效率稳定，（层数决定）
        3. 范围查询 可以只遍历叶子结点（有双向的指针）。
   - B+ 树索引（高扇出，2-4次IO）
     - 聚簇索引
         `如果表设置了主键，则主键就是聚簇索引
          * 如果表没有主键，则会默认第一个NOT NULL，且唯一（UNIQUE）的列作为聚簇索引
          * 以上都没有，则会默认创建一个隐藏的row_id作为聚簇索引
          * 叶子结点存储的是行记录`
        1. 叶子结点是数据页，存放所有数据。
        2. 非数据页的索引页，存放的是key value和数据页的偏移量 
        3. 存储上并不是物理上连续的，是逻辑上连续的。
     - 非聚簇索引
        1. 叶子结点存放key value 及主键索引的主键。 如果树高度为3，通过非聚集索引，查找次数为6。
     - 联合索引
        1. 通过类似元组的方式组合的键 (x, y)
        2. 联合索引对第二个键进行了排序。
        3. 建了联合索引a b，和单索引a 查询a时会走到索引a，理论上的一个页存的记录会更多
        4. select * from xxx where a=xx order by b  b有索引更好
     - 覆盖索引
        1. 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
        2. 如果 a,b 索引，只查b的统计，而b又没有单独列索引，那就会走到a，b索引
     
     - 不走索引的情况
        1. 多放生于范围查找, join
        2. 顺序读远远快于离散读，大量获取数据时，可能不会走索引

     - Multi-Range Read 优化： 减少随机访问 ，尽量给结果的主键排序，按排序的顺序查找。
     - Index Condition Pushdown(ICP) 
       `where 条件下推，检索出所有数据再过滤`
   - 哈希索引
     - “自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。
   - 全文索引&倒排索引 todo
   
   - 索引优化 
     - 独立的列，查询不能用表达式
     - 多列索引 多列查询时
     - 索引顺序
     - 前缀索引 text
     - 覆盖索引 索引包含了所有要查的字段的值
     
   - explain 指标
     - select type:  SIMPLE 简单查询，UNION 联合查询，SUBQUERY 子查询等。
     - possible_keys 可选择的索引
     - key 实际走的索引
     - rows 扫描的行数
     - type
         - ref： 使用非唯一索引
         - range：使用主键、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询
         - index：和all的区别是扫描的是索引树
         - all：扫描全表
         
   - 查询优化：
     - 切分大查询
     - 分解大连接查询：多join改成应用层连接 缓存更高效，减少锁竞争。
   
### 锁
  - 管理对共享资源的并发访问
  - 加锁的资源：缓冲池的LRU列表，删除，添加移动LRU列表的元素。 行级别对表加锁。
  - lock与latch
    - latch 对象是线程。一般称为闩锁(轻量级的锁), 要求锁定的时间必须非常短。
      保证并发线程操作临界资源的正确性。
      `latch争用过程
       
       1. a 以x访问链表
       
       2. b 排队等待x解锁  占了cpu，但是cpu发现你在等待，所以cpu将b踢出
       
       3. 锁链的时间，就是找数据的时间。
       
       4. b知道很a快所以，b不去排队，这是后去spin 也就是空转cpu，然后再去看一下内存数据结构，a是否已解锁
       
       5. b转了一圈后，在b spin的时间段的时间中，c进来了，连续多次的spin后， 产生了os waits
       
       6. 操作系统将b从cpu中踢出
       
       latch锁特点：
       
       1. 不排队
       2. spin
       3. os waits
       4. cpu繁忙
       `
       
      1. mutex 互斥量（排他锁） 资源需要共享和并发，但不频繁。
      ` 内存结构 很小 数据库从操作系统申请到的，不占用buffer pool，完全排他
   
        mutex锁的持有过程:　
       
        - a线程持有想mutex内存数据结构中写一个1
       
        - b线程看到内存数据结构有数字， 那么就去spin`
      2. rw latch 读写锁 
      `latch争用的过程
       
       链表上有一个链的保护机制latch，小内存结构，这时候有读的线程a上来要读取链，这个时候这个管理就变成r，读锁，当在链上找到数据的时候(读)，
       一找到就释放读锁，b上来也要读取，这时候一看是r，读锁是可以共享的，她也是对链进行访问读取的，c上来要修改链中的两个块的内容，
       一看是r，r和w是互斥的，不能够同时进行，要么
       
       1. 主动要求退出cpu
       
       2. 空占着cpu资源（执行一段空代码，loop，隔一段时间看看a和b有没有使用完(spin)，
       但是在这个过程中因为c没有排队等待，所以可能在等待的过程中又有其他的线程上来霸占链，
       如果执行多次仍这样，可能就sleep，退出cpu了）为什么空占（害怕操作系统看她闲的把他强行拖走），
       等（因为他知道a和b占用了资源时间比较短，就是遍历一条链的时间非常短）。
       
       latch争用的现象：
       
        1. latch争用会表现为cpu繁忙
       
        2. latch争用没有排队，等一段随机的时间再回来看一看`
        
    - lock 
      - 对象是事务，用来锁定的是数据库中的对象，如表，页，行。
      - lock的对象仅在事务commit 或 rollback进行释放。
      - 有死锁机制
      - 超时释放死锁
      - wait-for graph （等待图）检查死锁
      
    ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633190344877.png)
  
  - innodb中的锁
    - 共享锁  (S LOCK） 读
    - 排他锁  (X LOCK)  写
      [加锁的实现](http://mysql.taobao.org/monthly/2020/04/02/)
      `
      使用原子操作+自旋的模式来实现加解锁，这样可以在低冲突的场景下，以尽量小的开销实现加解锁。遇到实在是冲突高的读写锁，再使用InnoDB条件变量实现等待`
    - 意向锁 （Intention Lock）
      `类似表锁 获取行锁之前，先获取一下粗力度的锁`
      - IS LOCK
      - IX LOCK
      ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633197053729.png)
    
    - 一致性非锁定读
        `mvcc 实现。 如果读取的行正在执行delete/update, 这时读取操作不会因此去等待行锁释放，而去读一个快照读的数据`
        `通过快照读，实现是通过undo段来完成。快照数据不需要上锁，没有事务需要对历史数据进行修改`
        `读已提交下： 快照数据，非一致性读总是读取被锁定行的最新一份快照数据`
        `可重复读下: 非一致性读总是读取事务开始时的行数据版本`
        ![两事务读取过程](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633245392477.png)
    
    - 一致性锁定读
      - select ... for update X锁
        `有主-从表的这种情况, 比如想在从表insert一条记录, 需要先将主表相关的数据加S锁锁定, 然后再insert从表, 
        来实现主从表数据一致性, 即有可能其他session会再此时delete主表的这条数据而造成只有从表有数据而主表无数据的数据不一致结果`
      - select ... LOCK IN SHARE MODE S锁
        `多个session的事务要对同一个表的一/多条数据进行更新操作的时候, 要先锁定再更新来消除并发造成的数据不一致`
      - 用上面的语句 需要加上begin 开启事务
    - 自增长与锁
      - innodb_autoinc_lock_mode
    - 外键和锁
      - 外键的修改/更新 使用的不是一致性非锁定读，避免发生数据不一致的问题。用的是S 锁。
        如果这时又一个X锁，则子表上的操作会阻塞。（主表正在删除，子表插入）
        
  - 锁的算法
    - record lock 行锁 锁的是索引记录
    - gap lock 间隙锁 锁定一个范围 但不包含记录本身
    - next-key lock: gap lock + record lock 锁定一个范围并锁定记录本身。
      `通过非聚簇索引检索， 加上的是next-key lock， 比如锁一个值x，会锁x的前一个值和后一个值的区间`
      - 加锁规则
      `原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。
      
       原则2：查找过程中访问到的对象才会加锁。
      
      优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
      
      优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
      
      一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。`
  - 锁问题
    - 脏读: 不同事务a事务读到了b的未提交的数据。 
    - 不可重复读: next-key lock解决。
    - 丢失更新: 操作需要串行化， 加X锁。 查询时加for update去阻塞。
  - 阻塞
    - 阻塞后，超时等抛出异常，因为没有commit/rollback，所以还在这个事务内，更改的记录还在。等待commit。
  - 死锁
    - 多个事务在执行的过程中，因争抢锁资源造成的一种互相等待的现象。
    - 解决办法
      1. 超时， 超时后按fifo进行会滚。(如果事务更新了很多行，占用了较多undolog，回滚这个事务就会比其他的慢)
      2. wait-for graph(等待图)
        - 锁的信息链表
        - 事务等待链表
        - 在每个事务请求锁并发生等待时，都会判断是否存在回路， 若存在则有死锁。 innodb会选择回滚undo量较小的事务。
        - 通过深度优先算法实现，优化后非递归。
    - 发生死锁后，会选1个undolog相对少的事务进行回滚
    - 死锁概率
    - 锁升级 lock escalation
      `在锁开销过大的时候，会升级成更高粒度的锁，比如行锁变表锁`
      - 触发节点
        1. 锁占用内存超过了激活内存的40%
        2. 一个对象上持有的锁数量超过了阈值，默认5000。不同对象不会升级。
    
### 事务
  - 确保所有的修改都已经保存了，要么所有的修改都不保存
  - 事务特性 ACID
    - 原子性 atomicity: 要么多走，要么都不做。
    - 一致性 consistency： 事务开始前和结束后，数据库的完整性约束不会被破坏。比如有唯一键，事务提交/会滚后依然要保持唯一性。
    - 隔离性 isolation (锁)： 并发控制/锁/可串行化
    - 持久性 durability: 事务一旦提交，就是永久性的，可恢复。
    
  - 事务分类
    - 扁平事务（顺序执行）
    - 带保存点的扁平事务，支持会滚到同1事务的焦躁的一个状态。
    - 链事务， 非持久性的。
    - 分布式事务 
    
  - 事务实现
    - 重做日志
        - redo log
          - innodb 引擎层带的日志
          - 当事务提交时，必须讲该事务的所有日志全部写完到重做日志里（写日志的过程是在事务执行过程中实时的）
          - 保证事务的持久性，崩溃后可恢复。
          - 和bin log 需要保持一致，所以有两段式提交
            1. 获取行数据
            2. 修改行数据
            3. 写入新行
            4. 新行更新到内存
            5. 写入redolog 处于prepare阶段
            6. 写入bin log
            7. commit
          - 恢复
            1. 如果redolog 完整 有commit 直接提交
            2. 如果redolog 只有prepare， 判断binlog是否完整来决定是否提交。
          - fsync
            - 类似同步的写磁盘机制，写入磁盘后要确认是否写完才返回。不是异步的。
            - 在每次将重做日志缓冲写入重做日志文件时，都要掉用fsync。 磁盘的性能决定了事务的提交性能，也就是数据库性能。
            - 也可以配置不实时fsync，可以定时fsync，但是会丢一部分事务。
            - 配置innodb_flush_log_at_trx_commit 
              - 1: 必须调用
              - 0: 主线程1s1次
              - 2: 事务提交时只写入文件系统的缓存中（sync），文件系统自行处理。操作系统不宕机不丢数据。
            - 为了提升提交性能，类似批量插入的，最好一次性commit，不要挨个commit。
            
            - 与binlog的区别：
               - binlog
                 1. mysql数据库上层产生的
                 2. 逻辑日志 commit
               - 重做日志
                 1. innodb引擎层的日志。
                 2. 物理格式日志，记录的每个页的修改
          - log block
            - 重做日志块小于512字节 和磁盘扇区大小一样，写入是原子性的，不需要双写。
            - log buffer 由log block组成的数组。
          - log group 
            - 在innodb运行过程中， log buffer根据一定的规则将内存中的log block刷到磁盘上。
              1. 事务提交时
              2. log buffer中有一半的内存空间已经被使用时
              3。 log checkpoint 时
          - 恢复
            - 启动时都会尝试进行恢复。
            - 物理日志 速度快
            - 顺序读取，并行应用重做日志。
            - checkpoint 内存中的未写入日志文件的（脏页） 刷到磁盘
        
        - undo log 
          - 事务回滚 
          - undo 存放在数据库内部的特殊段 segment
          - 在共享表空间
          - undo是逻辑日志 所有修改都被逻辑地取消
          - 回滚的时候，执行一个反向操作 insert/delete update/反update
          - mvcc 用户读取一行记录时，如果该记录被其他食物占用，当前事务可以通过undo读到之前的行版本信息，实现了非锁定读取。
          - undo log也会产生redolog， undo log也需要持久性的维护。
          - 事务在undo log segment 分配页 写入undolog 并同样需要写入重做日志。
          - insert undo log 记录insert
          - update undo log 记录update/delete。事务提交时，等待purge线程进行删除。
          
        - purge 清除
          - delete 时 只是将delete flag 置为1。记录没有被删除，还在b+树中。辅助索引也没有删除。
          - purge 用于最终完成delete 和update。
          - 支持mvcc，删除/修改不能在事务提交时立即处理， 其他事务可能正在饮用者一样，innodb 需要保存记录之前的版本。
            `如果该行记录不再被任何其他事务占用，则可以进行真正的删除`
          - 先从history list中找 undolog 再从 undo page 中找undo log 避免大量的随机读写。
        - group commit  
    - 隔离级别（每一种的实现原理？）
      - read uncommitted 读未提交：脏读。 事务中的修改，没提交对其他事务也是可见的。 
      - read committed 读已提交: 不可重复读 事务只能读取已经提交的事务所做的修改
        `事务A执行过程中,事务B完成了提交，A再select可以读到，导致不可重复读`
        加锁，不加间隙锁
      - repeatable read 可重复读：会导致幻读 保证同一个事务中 多次读取同样的数据结果是一样的 通过MVCC来解决幻读
        `MVCC + next key lock 解决了幻读`
        `事务A执行过程中,事务B完成了提交，A再select读不到`
      - serializable 可串行化 强制事务串行执行 通过给读取到的每一行数据都加上锁。
    - mvcc  
      - 每行记录后面有两个隐藏的列，1个创建时间，一个删除时间， 存储的事系统版本号。 每一个新的事务，都会自动新增版本号。
      - 可重复读下mvcc的流程。
      `当开启一个新的事务时，该事务的版本号肯定大雨当前所有数据行快照的创建版本号`
        1. select 
            `InnoDB会根据以下条件检查每一行记录：`
            1. InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行要么是在开始事务之前已经存在要么是事务自身插入或者修改过的，在事务开始之后才插入的行，事务不会看到。
            
            2. 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以 确保事务读取到的行在事务开始之前未被删除，在事务开始之前就已经过期的数据行，该事务也不会看到。
            只有符合上述两个条件的才会被查询出来
        2. INSERT
        将当前系统版本号作为数据行快照的创建版本号。
        3. DELETE
        将当前系统版本号作为数据行快照的删除版本号。
        4. UPDATE
        将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。 可以理解为先执行 DELETE 后执行 INSERT。
        保存这两个版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且能保证只会读取到复合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。

        MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。
        
        可以认为MVCC是行级锁一个变种，但是他很多情况下避免了加锁操作，开销更低。虽然不同数据库的实现机制有所不同，但大都实现了非阻塞的读操作（读不用加锁，且能避免出现不可重复读和幻读），写操作也只锁定必要的行（写必须加锁，否则不同事务并发写会导致数据不一致）。
    - 快照读与当前读
    `在RR级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，不是数据库最新的数据。这种读取历史数据的方式，我们叫它 快照读 (snapshot read)，而读取数据库最新版本数据的方式，叫 当前读 (current read)。`
        1. 快照读
        
        当执行select操作是innodb默认会执行快照读，会记录下这次select后的结果，之后select 的时候就会返回这次快照的数据，即使其他事务提交了不会影响当前select的数据，这就实现了可重复读了。快照的生成当在第一次执行select的时候，也就是说假设当A开启了事务，然后没有执行任何操作，这时候B insert了一条数据然后commit,这时候A执行 select，那么返回的数据中就会有B添加的那条数据。之后无论再有其他事务commit都没有关系，因为快照已经生成了，后面的select都是根据快照来的。
        使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。
        
        2. 当前读
        
        对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式。在执行这几个操作时会读取最新的记录，即使是别的事务提交的数据也可以查询到。假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。
        读取的是最新的数据，需要加锁。以下第一个语句需要加 S（共享锁） 锁，其它都需要加 X（排他锁） 锁。
        select * from table where ? lock in share mode; 
        select * from table where ? for update; 
        insert; 
        update; 
        delete;复制代码
            
##存储解决方案
- Redis与MySQL双写一致性如何保证[双写一致性](https://www.cnblogs.com/rjzheng/p/9041659.html)
    
    从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。
    三种更新策略：
    
    1. 先更新数据库，再更新缓存(不建议)
        - 线程不安全，多线程更新数据，会导致缓存更新和数据库更新不一致
        - 业务：1.如果是写多读少，频繁更新，浪费。2.如果更新缓存需要计算，浪费性能。
    
   2. 先删除缓存，再更新数据库
        - 导致数据不一致 操作如下
           (1）请求A进行写操作，删除缓存
          （2）请求B查询发现缓存不存在
          （3）请求B去数据库查询得到旧值
          （4）请求B将旧值写入缓存
          （5）请求A将新值写入数据库
        - 解决：延时双删
           `
           （1）先淘汰缓存
           （2）再写数据库（这两步和原来一样）
           （3）休眠1秒（写数据的休眠时间>读业务的耗时xxx ms），再次淘汰缓存
          
           public void write(String key,Object data){
            		redis.delKey(key);
            	    db.updateData(data);
            	    Thread.sleep(1000);
            	    redis.delKey(key);
            	}
            	
           ` 
           - 同步删除：吞吐量降低，改成异步删除
           - mysql读写分离架构: 增加双删延时
           - 第二次删除,如果删除失败怎么办？: 先更库，再更缓存。
           
    3. 先更新数据库，再删除缓存
        - 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
        - 命中：应用程序从cache中取数据，取到后返回。
        - 更新：先把数据存到数据库中，成功后，再让缓存失效。
        - 这种情况不存在并发问题么？
        不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生
        （1）缓存刚好失效
        （2）请求A查询数据库，得一个旧值
        （3）请求B将新值写入数据库
        （4）请求B删除缓存
        （5）请求A将查到的旧值写入缓存
        ok，如果发生上述情况，确实是会发生脏数据。
        然而，发生这种情况的概率又有多少呢？
        发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。
        假设，有人非要抬杠，有强迫症，一定要解决怎么办？
        - 如何解决上述并发问题？
        首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。
        还有其他造成不一致的原因么？
        有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。
        - 如何解决缓存删除失败？
        提供一个保障的重试机制即可，这里给出两套方案。
    
    4. 重试机制
      删除失败的消息入队列，等待删除，配置好过期时间，重试次数等。
      - 业务实现：耦合高
        ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632655411407.png)
      - binlog实现：可以订阅binlog，但是结构变了会有影响，依赖于结构。
        ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632655397729.png)
    
    
    

## 资料
[mysql](https://aobing.blog.csdn.net/article/details/109257302)

[数据库知识点](https://aobing.blog.csdn.net/article/details/109063250)

- 索引[索引](https://aobing.blog.csdn.net/article/details/108436939)
    
    [MySQL如何设计索引更高效](https://aobing.blog.csdn.net/article/details/112451981)
    
    [delete?](https://aobing.blog.csdn.net/article/details/109735448)
  
    [text](https://aobing.blog.csdn.net/article/details/109569211)

    [数据库调优](https://juejin.cn/post/6844904201437315079)
- [事务&MVCC](https://aobing.blog.csdn.net/article/details/106915564)


[mysql安全](https://aobing.blog.csdn.net/article/details/110383085)