
## MYSQL
         
### 插件式存储引擎
   - InnoDB
     - mysql默认的事务型存储引擎(OLAP)
     - MVCC支持高并发
     - 四个标准隔离级别(未提交读、提交读、可重复读、可串行化)。
         `其默认级别时可重复读（REPEATABLE READ），在可重复读级别下，通过 MVCC + Next-Key Locking 防止幻读。`
     - 主索引是聚簇索引 索引中保存了数据，避免再次读盘。
     - 插入缓冲 二次写 自适应哈希索引 预读
     - 优化 从磁盘读取数据时采用的可预测性读，能够自动在内存中创建 hash 索引以加速读操作的自适应哈希索引，以及能够加速插入操作的插入缓冲区等。
     - 在线热备份: MySQL 其他的存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合的场景中，停止写入可能也意味着停止读取。
   - MyISAM
     - 索引 B+tree 主索引：非聚簇索引（因为数据紧密格式存储）
     `设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。
      
      提供了大量的特性，包括压缩表、空间数据索引等。
      
      不支持事务。
      
      不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。
      
      可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。
      
      如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。`
   - InnoDB 和 MyISAM 的比较
        - 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
   
        - 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
   
        - 外键：InnoDB 支持外键。
   
        - 备份：InnoDB 支持在线热备份。
   
        - 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
   
        - 其它特性：MyISAM 支持压缩表和空间数据索引。
    - NDB集群存储引擎 share notion过架构的集群 数据全放在内存，非索引可以放在次盘。 join实在数据库层完成的，查询速度慢
    - Memory 存在内存里
    
### InnoDB体系结构
    ![innodb存储引擎体系架构](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633269283438.png)
    - 维护所有进程/线程需要访问的多个内部数据结构
    - 缓存磁盘上的数据，方便快速读取。数据修改之前先缓存
    - 重做日志。
    
  - 后台线程
    1. Master Thread
        
        `主要负责缓冲池的数据异步刷新到磁盘，保证数据一致性，脏页的刷新，合并插入缓冲，undo页的回收等`
    
    2. IO thread 
        `异步io，async`
    3. Purege Thread 
        `回收已经使用并分配的undo页`
    4.Page Cleaner Thread
        `脏页刷到文件中`
    
  - 内存
    - 缓冲池
      - 读取: 首先将磁盘读取到的页放在缓存池中，再次读取时，如果该页在缓存池中，则命中，读取。
      - 修改: 首先修改缓冲池的页，再以一定的频率刷到磁盘上。（通过checkpoint刷到磁盘）
      - 缓存的数据页类型: 索引页， 数据页，undo页，插入缓冲，自适应哈希索引，锁，等。
        ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633271465564.png)
    - LRU List, Free List, Flush List
      - LRU List
        `innodb 加入了midpoint 新读到的页驾到LRU的中间点位置
        配置innodb_old_blocks_time，表示读到mid位置后需要等待多久才会被加入到LRU顶端
        `
      - Free List 空闲的缓存页链表
      - Flush List 缓冲池的页和磁盘上的页的数据不一致，通过checkpoint机制 将脏页刷新回磁盘。
  
  - checkpoint
    
  - [BufferPool](https://mp.weixin.qq.com/s/4ZZ_xWI-oPX735cMF_UBMw)
    
### 索引
   - B+ Tree 原理
     - 平衡树 + 顺序查找
     - 内部节点（索引节点）和叶子结点 叶子节点存数据
     - 节点的key 左子树都小于他 右子树都大于他
     - 多列索引/联合索引  a,b,c  a作为b+树节点，b，c作为叶子结点的值，保持有序
     - 查找
     
     `查找以典型的方式进行，类似于二叉查找树。起始于根节点，自顶向下遍历树，选择其分离值在要查找值的任意一边的子指针。在节点内部典型的使用是二分查找来确定这个位置。`
     - 插入：必须保证插入后叶子结点的记录依然有序
     ![插入的三种情况](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632734966459.png)
        1. 叶子结点没满 直接插入叶子结点
        2. 叶子结点满了 索引节点没满 拆分叶子page 拆成两块
        3. 叶子结点和索引节点都满了: 拆分叶子结点的page 再拆分索引节点的page
        4. 旋转 leaf page已满 但是左右兄弟没满，会记录转移到兄弟节点上，左兄弟会用来做旋转
     - 删除: 保证删除后有序 填充因子（最小50%）
        ![删除的三种情况](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632736824521.png)
     - 特点：
        1. 磁盘io低，非叶子节点只存放索引，一次性读入内存的需要查找的关键字多。
        2. 查询效率稳定，（层数决定）
        3. 范围查询 可以只遍历叶子结点（有双向的指针）。
   - B+ 树索引（高扇出，2-4次IO）
     - 聚簇索引
         `如果表设置了主键，则主键就是聚簇索引
          * 如果表没有主键，则会默认第一个NOT NULL，且唯一（UNIQUE）的列作为聚簇索引
          * 以上都没有，则会默认创建一个隐藏的row_id作为聚簇索引
          * 叶子结点存储的是行记录`
        1. 叶子结点是数据页，存放所有数据。
        2. 非数据页的索引页，存放的是key value和数据页的偏移量 
        3. 存储上并不是物理上连续的，是逻辑上连续的。
     - 非聚簇索引
        1. 叶子结点存放key value 及主键索引的主键。 如果树高度为3，通过非聚集索引，查找次数为6。
     - 联合索引
        1. 通过类似元组的方式组合的键 (x, y)
        2. 联合索引对第二个键进行了排序。
        3. 建了联合索引a b，和单索引a 查询a时会走到索引a，理论上的一个页存的记录会更多
        4. select * from xxx where a=xx order by b  b有索引更好
     - 覆盖索引
        1. 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
        2. 如果 a,b 索引，只查b的统计，而b又没有单独列索引，那就会走到a，b索引
     
     - 不走索引的情况
        1. 多放生于范围查找, join
        2. 顺序读远远快于离散读，大量获取数据时，可能不会走索引
        3. like不满足前缀匹配
        4. 联合索引未命中
        5. 数据出现隐形转换，如varchar字段没加单引号，自动转为int类型，会使索引失效
        6. or查询，必须左右字段都是索引，否则索引失效
        7. 索引字段使用not、<>、!=，索引失效

     - Multi-Range Read 优化： 减少随机访问 ，尽量给结果的主键排序，按排序的顺序查找。
     - Index Condition Pushdown(ICP) 
       `where 条件下推，检索出所有数据再过滤`
   - 哈希索引
     - “自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。
   - 全文索引&倒排索引 todo
   
   - 索引优化 
     - 独立的列，查询不能用表达式
     - 多列索引 多列查询时
     - 索引顺序
     - 前缀索引 text
     - 覆盖索引 索引包含了所有要查的字段的值
     
   - explain 指标
     - select type:  SIMPLE 简单查询，UNION 联合查询，SUBQUERY 子查询等。
     - possible_keys 可选择的索引
     - key 实际走的索引
     - rows 扫描的行数
     - type
         - ref： 使用非唯一索引
         - range：使用主键、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询
         - index：和all的区别是扫描的是索引树
         - all：扫描全表
         
   - 查询优化：
     - 切分大查询
     - 分解大连接查询：多join改成应用层连接 缓存更高效，减少锁竞争。
   - 排序：
     - 走索引
     - 文件排序
       `文件排序是通过相应的排序算法，将取得的数据在内存中进行排序：MySQL需要将数据在内存中进行排序，
       所使用的内存区域也就是我们通过sort_buffer_size系统变量所设置的sort buffer(排序区)。
       这个sort buffer是每个Thread独享的，
       所以说可能在同一时刻在MySQL中可能存在多个sort buffer内存区域。`
       - 双路排序
        `第一遍扫描出需要排序的字段，然后进行排序后，根据排序结果，第二遍再扫描一下需要select的列数据。
        这样会引起大量的随机IO，效率不高，但是节约内存。排序使用quick sort，但是如果内存不够则会按照block进行排序，将排序结果写入磁盘文件，然后再将结果合并。`
       - 单路排序 
        `一次查出所有数据， 然后在sort buffer中排序，避免了双路排序的两次读的随机IO`
       - quicksort + 归并
      
     
### 锁
  - 管理对共享资源的并发访问
  - 加锁的资源：缓冲池的LRU列表，删除，添加移动LRU列表的元素。 行级别对表加锁。
  - lock与latch
    - latch 对象是线程。一般称为闩锁(轻量级的锁), 要求锁定的时间必须非常短。（自旋锁）
      保证并发线程操作临界资源的正确性。
      `latch争用过程
       
       1. a 以x访问链表
       
       2. b 排队等待x解锁  占了cpu，但是cpu发现你在等待，所以cpu将b踢出
       
       3. 锁链的时间，就是找数据的时间。
       
       4. b知道很a快所以，b不去排队，这是后去spin 也就是空转cpu，然后再去看一下内存数据结构，a是否已解锁
       
       5. b转了一圈后，在b spin的时间段的时间中，c进来了，连续多次的spin后， 产生了os waits
       
       6. 操作系统将b从cpu中踢出
       
       latch锁特点：
       
       1. 不排队
       2. spin
       3. os waits
       4. cpu繁忙
       `
       
      1. mutex 互斥量（排他锁） 资源需要共享和并发，但不频繁。
      ` 内存结构 很小 数据库从操作系统申请到的，不占用buffer pool，完全排他
   
        mutex锁的持有过程:　
       
        - a线程持有想mutex内存数据结构中写一个1
       
        - b线程看到内存数据结构有数字， 那么就去spin`
      2. rw latch 读写锁 
      `latch争用的过程
       
       链表上有一个链的保护机制latch，小内存结构，这时候有读的线程a上来要读取链，这个时候这个管理就变成r，读锁，当在链上找到数据的时候(读)，
       一找到就释放读锁，b上来也要读取，这时候一看是r，读锁是可以共享的，她也是对链进行访问读取的，c上来要修改链中的两个块的内容，
       一看是r，r和w是互斥的，不能够同时进行，要么
       
       1. 主动要求退出cpu
       
       2. 空占着cpu资源（执行一段空代码，loop，隔一段时间看看a和b有没有使用完(spin)，
       但是在这个过程中因为c没有排队等待，所以可能在等待的过程中又有其他的线程上来霸占链，
       如果执行多次仍这样，可能就sleep，退出cpu了）为什么空占（害怕操作系统看她闲的把他强行拖走），
       等（因为他知道a和b占用了资源时间比较短，就是遍历一条链的时间非常短）。
       
       latch争用的现象：
       
        1. latch争用会表现为cpu繁忙
       
        2. latch争用没有排队，等一段随机的时间再回来看一看`
        
    - lock 
      - 对象是事务，用来锁定的是数据库中的对象，如表，页，行。
      - lock的对象仅在事务commit 或 rollback进行释放。
      - 有死锁机制
      - 超时释放死锁
      - wait-for graph （等待图）检查死锁
      
    ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633190344877.png)
  
  - innodb中的锁
    - 共享锁  (S LOCK） 读
    - 排他锁  (X LOCK)  写
      [加锁的实现](http://mysql.taobao.org/monthly/2020/04/02/)
      `
      使用原子操作+自旋的模式来实现加解锁，这样可以在低冲突的场景下，以尽量小的开销实现加解锁。遇到实在是冲突高的读写锁，再使用InnoDB条件变量实现等待`
    - 意向锁 （Intention Lock）
      `类似表锁 获取行锁之前，先获取一下粗力度的锁`
      - IS LOCK
      - IX LOCK
      ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633197053729.png)
    
    - 一致性非锁定读
        `mvcc 实现。 如果读取的行正在执行delete/update, 这时读取操作不会因此去等待行锁释放，而去读一个快照读的数据`
        `通过快照读，实现是通过undo段来完成。快照数据不需要上锁，没有事务需要对历史数据进行修改`
        `读已提交下： 快照数据，非一致性读总是读取被锁定行的最新一份快照数据`
        `可重复读下: 非一致性读总是读取事务开始时的行数据版本`
        ![两事务读取过程](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633245392477.png)
    
    - 一致性锁定读
      - select ... for update X锁
        `有主-从表的这种情况, 比如想在从表insert一条记录, 需要先将主表相关的数据加S锁锁定, 然后再insert从表, 
        来实现主从表数据一致性, 即有可能其他session会再此时delete主表的这条数据而造成只有从表有数据而主表无数据的数据不一致结果`
      - select ... LOCK IN SHARE MODE S锁
        `多个session的事务要对同一个表的一/多条数据进行更新操作的时候, 要先锁定再更新来消除并发造成的数据不一致`
      - 用上面的语句 需要加上begin 开启事务
    - 自增长与锁
      - innodb_autoinc_lock_mode
    - 外键和锁
      - 外键的修改/更新 使用的不是一致性非锁定读，避免发生数据不一致的问题。用的是S 锁。
        如果这时又一个X锁，则子表上的操作会阻塞。（主表正在删除，子表插入）
        
  - 锁的算法
    - record lock 行锁 锁的是索引记录
    - gap lock 间隙锁 锁定一个范围 但不包含记录本身
    - next-key lock: gap lock + record lock 锁定一个范围并锁定记录本身。
      `通过非聚簇索引检索， 加上的是next-key lock， 比如锁一个值x，会锁x的前一个值和后一个值的区间`
      - 加锁规则
      `原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。
      
       原则2：查找过程中访问到的对象才会加锁。
      
      优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
      
      优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
      
      一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。`
  - 锁问题
    - 脏读: 不同事务a事务读到了b的未提交的数据。 
    - 不可重复读: next-key lock解决。
    - 丢失更新: 操作需要串行化， 加X锁。 查询时加for update去阻塞。
  - 阻塞
    - 阻塞后，超时等抛出异常，因为没有commit/rollback，所以还在这个事务内，更改的记录还在。等待commit。
  - 死锁
    - 多个事务在执行的过程中，因争抢锁资源造成的一种互相等待的现象。
    - 解决办法
      1. 超时， 超时后按fifo进行会滚。(如果事务更新了很多行，占用了较多undolog，回滚这个事务就会比其他的慢)
      2. wait-for graph(等待图)
        - 锁的信息链表
        - 事务等待链表
        - 在每个事务请求锁并发生等待时，都会判断是否存在回路， 若存在则有死锁。 innodb会选择回滚undo量较小的事务。
        - 通过深度优先算法实现，优化后非递归。
    - 发生死锁后，会选1个undolog相对少的事务进行回滚
    - 死锁概率
    - 锁升级 lock escalation
      `在锁开销过大的时候，会升级成更高粒度的锁，比如行锁变表锁`
      - 触发节点
        1. 锁占用内存超过了激活内存的40%
        2. 一个对象上持有的锁数量超过了阈值，默认5000。不同对象不会升级。
    
### 事务
  - 确保所有的修改都已经保存了，要么所有的修改都不保存
  - 事务特性 ACID
    - 原子性 atomicity: 要么都做，要么都不做。
    - 一致性 consistency： 事务开始前和结束后，数据库的完整性约束不会被破坏。比如有唯一键，事务提交/会滚后依然要保持唯一性。
    - 隔离性 isolation (锁)： 并发控制/锁/可串行化
    - 持久性 durability: 事务一旦提交，就是永久性的，可恢复。
    
  - 事务分类
    - 扁平事务（顺序执行）
    - 带保存点的扁平事务，支持会滚到同1事务的焦躁的一个状态。
    - 链事务， 非持久性的。
    - 分布式事务 
    
  - 事务实现
    - 重做日志
        - redo log
          - innodb 引擎层带的日志
          - 当事务提交时，必须讲该事务的所有日志全部写完到重做日志里（写日志的过程是在事务执行过程中实时的）
          - 保证事务的持久性，崩溃后可恢复。
          - 和bin log 需要保持一致，所以有两段式提交
            1. 获取行数据
            2. 修改行数据
            3. 写入新行
            4. 新行更新到内存
            5. 写入redolog 处于prepare阶段
            6. 写入bin log
            7. commit
          - 恢复
            1. 如果redolog 完整 有commit 直接提交
            2. 如果redolog 只有prepare， 判断binlog是否完整来决定是否提交。
          - fsync
            - 类似同步的写磁盘机制，写入磁盘后要确认是否写完才返回。不是异步的。
            - 在每次将重做日志缓冲写入重做日志文件时，都要掉用fsync。 磁盘的性能决定了事务的提交性能，也就是数据库性能。
            - 也可以配置不实时fsync，可以定时fsync，但是会丢一部分事务。
            - 配置innodb_flush_log_at_trx_commit 
              - 1: 必须调用
              - 0: 主线程1s1次
              - 2: 事务提交时只写入文件系统的缓存中（sync），文件系统自行处理。操作系统不宕机不丢数据。
            - 为了提升提交性能，类似批量插入的，最好一次性commit，不要挨个commit。
            
            - 与binlog的区别：
               - binlog
                 1. mysql数据库上层产生的
                 2. 逻辑日志 commit
               - 重做日志
                 1. innodb引擎层的日志。
                 2. 物理格式日志，记录的每个页的修改
          - log block
            - 重做日志块小于512字节 和磁盘扇区大小一样，写入是原子性的，不需要双写。
            - log buffer 由log block组成的数组。
          - log group 
            - 在innodb运行过程中， log buffer根据一定的规则将内存中的log block刷到磁盘上。
              1. 事务提交时
              2. log buffer中有一半的内存空间已经被使用时
              3。 log checkpoint 时
          - 恢复
            - 启动时都会尝试进行恢复。
            - 物理日志 速度快
            - 顺序读取，并行应用重做日志。
            - checkpoint 内存中的未写入日志文件的（脏页） 刷到磁盘
          - 数据库宕机重启后,会将redolog数据恢复到数据库中,再根据undo log和binlog内容决定是回滚事务还是提交事务.
            
        - undo log 
          - 事务回滚 
          - undo 存放在数据库内部的特殊段 segment
          - 在共享表空间
          - undo是逻辑日志 所有修改都被逻辑地取消
          - 回滚的时候，执行一个反向操作 insert/delete update/反update
          - mvcc 用户读取一行记录时，如果该记录被其他事务占用，当前事务可以通过undo读到之前的行版本信息，实现了非锁定读取。
          - undo log也会产生redolog， undo log也需要持久性的维护。
          - 事务在undo log segment 分配页 写入undolog 并同样需要写入重做日志。
          - insert undo log 记录insert
          - update undo log 记录update/delete。事务提交时，等待purge线程进行删除。
          
        - purge 清除
          - delete 时 只是将delete flag 置为1。记录没有被删除，还在b+树中。辅助索引也没有删除。
          - purge 用于最终完成delete 和update。
          - 支持mvcc，删除/修改不能在事务提交时立即处理， 其他事务可能正在引用者一样，innodb 需要保存记录之前的版本。
            `如果该行记录不再被任何其他事务占用，则可以进行真正的删除`
          - 先从history list中找 undolog 再从 undo page 中找undo log 避免大量的随机读写。
        - group commit  
    - 隔离级别（每一种的实现原理？）
      - read uncommitted 读未提交：脏读。 事务中的修改，没提交对其他事务也是可见的。 
      - read committed 读已提交: 不可重复读 事务只能读取已经提交的事务所做的修改
        `事务A执行过程中,事务B完成了提交，A再select可以读到，导致不可重复读`
        加锁，不加间隙锁
      - repeatable read 可重复读：会导致幻读 保证同一个事务中 多次读取同样的数据结果是一样的 通过MVCC来解决幻读
        `MVCC + next key lock 解决了幻读`
        `事务A执行过程中,事务B完成了提交，A再select读不到`
      - serializable 可串行化 强制事务串行执行 通过给读取到的每一行数据都加上锁。
    - mvcc  
      - 每行记录后面有两个隐藏的列，1个创建时间，一个删除时间， 存储的是系统版本号。 每一个新的事务，都会自动新增版本号。
      - 可重复读下mvcc的流程。
      `当开启一个新的事务时，该事务的版本号肯定大于当前所有数据行快照的创建版本号`
        1. select 
            `InnoDB会根据以下条件检查每一行记录：`
            1. InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行要么是在开始事务之前已经存在要么是事务自身插入或者修改过的，在事务开始之后才插入的行，事务不会看到。
            
            2. 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以 确保事务读取到的行在事务开始之前未被删除，在事务开始之前就已经过期的数据行，该事务也不会看到。
            只有符合上述两个条件的才会被查询出来
        2. INSERT
        将当前系统版本号作为数据行快照的创建版本号。
        3. DELETE
        将当前系统版本号作为数据行快照的删除版本号。
        4. UPDATE
        将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。 可以理解为先执行 DELETE 后执行 INSERT。
        保存这两个版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且能保证只会读取到复合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。

        MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。
        
        可以认为MVCC是行级锁一个变种，但是他很多情况下避免了加锁操作，开销更低。虽然不同数据库的实现机制有所不同，但大都实现了非阻塞的读操作（读不用加锁，且能避免出现不可重复读和幻读），写操作也只锁定必要的行（写必须加锁，否则不同事务并发写会导致数据不一致）。
    - 快照读与当前读
    `在RR级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，不是数据库最新的数据。这种读取历史数据的方式，我们叫它 快照读 (snapshot read)，而读取数据库最新版本数据的方式，叫 当前读 (current read)。`
        1. 快照读
        
        当执行select操作是innodb默认会执行快照读，会记录下这次select后的结果，之后select 的时候就会返回这次快照的数据，即使其他事务提交了不会影响当前select的数据，这就实现了可重复读了。快照的生成当在第一次执行select的时候，也就是说假设当A开启了事务，然后没有执行任何操作，这时候B insert了一条数据然后commit,这时候A执行 select，那么返回的数据中就会有B添加的那条数据。之后无论再有其他事务commit都没有关系，因为快照已经生成了，后面的select都是根据快照来的。
        使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。
        
        2. 当前读
        
        对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式。在执行这几个操作时会读取最新的记录，即使是别的事务提交的数据也可以查询到。假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。
        读取的是最新的数据，需要加锁。以下第一个语句需要加 S（共享锁） 锁，其它都需要加 X（排他锁） 锁。
        select * from table where ? lock in share mode; 
        select * from table where ? for update; 
        insert; 
        update; 
        delete;复制代码
    
### 主从
#### [主从同步](https://blog.csdn.net/ZHY_ERIC/article/details/123344246)
   - 解决问题
   - 适用场景: 主从同步
   - 同步流程
     - 主库2阶段提交
       - 记录undolog
       - 记录redolog （prepare）
       - 记录binlog
       - dump-thread 同步到从库
       - 记录redolog commit
     - 从库同步
       - iothread读到dump-thread 的内容 
       - 写入relay log
       - sql-thread写入数据库
   - binlog 3种格式   
     - statement
       - 直接记录语句 直接恢复可能会有问题，因为查询的不带主键
     - row
       - 每行的变动 
       - 占空间
     - mixed
       - MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。
   - 循环复制
     - 解决循环读binlog的问题 
     - 通过serverid成环检测解决
     
        
    
## tidb
### 为什么要用tidb
  - [对比mysql](https://blog.csdn.net/Itissohardtog/article/details/103197730)  
    mysql 集群方案较差 单机读写如到了瓶颈 则考虑替换  
    mysql cluster 最高只支持到read commited
  - tidb 优点
    TIDB核心特点：
    - 高度兼容MySql  
    大多数情况下，无需修改代码即可从MySql轻松迁移至TiDB，分库分表后的MySql集群亦可通过TiDB工具进行实时迁移。
    - 水平弹性扩展  
    通过简单地增加新节点即可实现TiDB的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。
    - 分布式事务  
    TiDB 100% 支持标准的ACID事务。
    - 真正金融级高可用  
    相比于传统主从（M-S）复制方案，基于Raft的多数派选举协议可以提供金融级的100%数据强一致性保证，且在不丢失大多数读本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。
    - 一站式HTAP解决方案  
    TiDB作为典型的OLTP（联机事务处理）行存数据库，同事兼具强大的OLAP（联机分析处理）性能，配合TiSpark，可提供一站式HTAP解决方案，一份存储同时处理OLTP&OLAP无需传统繁琐的ETL过程。
  - 常见问题
    - 锁  
      Percolator事务模型 锁是乐观锁实现，事物提交的时候才加锁。
      会导致row affect 为1 但是实际并没有成功
    - 3.08版本后默认悲观锁 但没有实现间隙锁
    - 不支持share mode
  - 场景
    1. 单机mysql有性能瓶颈
    2. 单表超2kw(mysql 2kw以上开始性能变差，因为b+树层数增加)
  
                                                     

### 整体架构[架构](https://docs.pingcap.com/zh/tidb/stable/tidb-architecture)
   - 架构图
   ![架构图](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1634133753553.png)
   - 架构
   - TiDB Server：  
     - 作为客户端链接 对外暴露endpoint 
     - sql解析 优化 生成分布式执行计划
     - 可以提供负载均衡
     
   
   - PD (Placement Driver) Server： 引擎层
      - 存储每个tikv节点实时的数据分布情况
      - 管理集群的整体拓扑结构
      - 提供全局唯一的分布式事务id
      - 调度tikv 节点
      - 高可用 3+个奇数节点
      
   - 存储节点
     - TiKV Server： 
       - 存储数据 
       - 分布式的提供食物的kv存储引擎
       - 数据的基本单位是region
       - 每个region负责存储1个key range 
       - 提供 Snapshot Isolation 隔离级别 支持acid
       - 多副本
     - TiFlash：
       TiFlash 是一类特殊的存储节点。和普通 TiKV 节点不一样的是，在 TiFlash 内部，数据是以列式的形式进行存储，主要的功能是为分析型的场景加速。
   - region （虚拟的）一个rocksdb会有多个region
     - Range：按照 Key 分 Range，某一段连续的 Key 都保存在一个存储节点上。
       - 将数据划分成 Region 后，TiKV 将会做两件重要的事情：
         以 Region 为单位，将数据分散在集群中所有的节点上，并且尽量保证每个节点上服务的 Region 数量差不多。
         以 Region 为单位做 Raft 的复制和成员管理。
   - MVCC 
     - Key1_Version3 -> Value
     

### 存储
  - TIKV  
    - 单机引擎rocksdb
    - 基于 LevelDB 开发的一款提供键值存储与读写功能的 LSM-tree 架构引擎
    - 用户写入的键值对会先写入磁盘上的 WAL (Write Ahead Log)，
    然后再写入内存中的跳表（SkipList，这部分结构又被称作 MemTable）。
    LSM-tree 引擎由于将用户的随机修改（插入）转化为了对 WAL 文件的顺序写，因此具有比 B 树类存储引擎更高的写吞吐。
    - 内存中的数据达到一定阈值后，会刷到磁盘上生成 SST 文件 (Sorted String Table)，
    SST 又分为多层（默认至多 6 层），每一层的数据达到一定阈值后会挑选一部分 SST 合并到下一层，
    每一层的数据是上一层的 10 倍（因此 90% 的数据存储在最后一层）。
    - RocksDB 
      `允许用户创建多个 ColumnFamily ，这些 ColumnFamily 各自拥有独立的内存跳表以及 SST 文件，但是共享同一个 WAL 文件，
      这样的好处是可以根据应用特点为不同的 ColumnFamily 选择不同的配置，但是又没有增加对 WAL 的写次数。`
      - 每个tikv有2个rocks db
      - kvdb中四个columnfamily
        - raft列：   
        存储region的元信息。
        - lock列：   
        用于存储悲观事务的悲观锁以及分布式事务的一阶段 Prewrite 锁。当用户的事务提交之后，
        lock cf 中对应的数据会很快删除掉，因此大部分情况下 lock cf 中的数据也很少（少于 1GB）。
        如果 lock cf 中的数据大量增加，说明有大量事务等待提交，系统出现了 bug 或者故障。
        - write 列:   
        用于存储用户真实的写入数据以及 MVCC 信息（该数据所属事务的开始时间以及提交时间）。当用户写入了一行数据时，如果该行数据长度小于 255 字节，那么会被存储 write 列中，否则的话该行数据会被存入到 default 列中。由于 TiDB 的非 unique 索引存储的 value 为空，unique 索引存储的 value 为主键索引，因此二级索引只会占用 writecf 的空间。
        - default 列：  
        用于存储超过 255 字节长度的数据
    - 映射到kv
      ```
      首先每行数据都会映射为一个 (Key, Value) 键值对，同时该表有一个 int 类型的主键，所以 RowID 的值即为该主键的值。假设该表的 TableID 为 10，则其存储在 TiKV 上的表数据为：
    
      t10_r1 --> ["TiDB", "SQL Layer", 10]
      t10_r2 --> ["TiKV", "KV Engine", 20]
      t10_r3 --> ["PD", "Manager", 30]
      除了主键外，该表还有一个非唯一的普通二级索引 idxAge，假设这个索引的 IndexID 为 1，则其存储在 TiKV 上的索引数据为：
      
      t10_i1_10_1 --> null
      t10_i1_20_2 --> null
      t10_i1_30_3 --> null
    ```
  - 架构
    ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1655804042918.png)
    
  - 索引 [LSM-TREE](https://cloud.tencent.com/developer/article/1441835)
    - 顺序写入，不存在删除和修改， 写友好，适合读多写少
      - 先写内存，在写磁盘 批量聚合写入 单条写性能差
      -（1） 数据是被整体访问的，大多数数据库的WAL（write ahead log）也称预写log，包括mysql的Binlog等
      -（2） 数据是通过文件的偏移量offset访问的，比如Kafka。
    - 数据结构： SSTable
    `SSTable是一种拥有持久化，有序且不可变的的键值存储结构，它的key和value都是任意的字节数组，
    并且了提供了按指定key查找和指定范围的key区间迭代遍历的功能。
    SSTable内部包含了一系列可配置大小的Block块，典型的大小是64KB，关于这些Block块的index存储在SSTable的尾部，
    用于帮助快速查找特定的Block。当一个SSTable被打开的时候，index会被加载到内存，然后根据key在内存index里面进行一个二分查找，
    查到该key对应的磁盘的offset之后，然后去磁盘把响应的块数据读取出来。当然如果内存足够大的话，
    可以直接把SSTable直接通过MMap的技术映射到内存中，
    从而提供更快的查找。 `
    - 查询：
      - 1，当收到一个读请求的时候，会直接先在内存里面查询，如果查询到就返回。
      - 2，如果没有查询到就会依次下沉，知道把所有的Level层查询一遍得到最终结果。
      - 优化
        - 压缩
        - 缓存
        - 索引
        - bloom filters
        - 合并
    ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1655809833916.png)
    
    ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1634132907946.png)
    [lsm-tree 对比 b+ tree](https://blog.csdn.net/weixin_33742618/article/details/91963547)
  - 查询 
    - 如果需要查询 (a=1 且 b=1）或 c=2 的数据 tidb 会用 `SELECT id from t_test where (a=1 and b=1) UNION SELECT id from t_test where (c=2);`
  
 
### 计算

### 调度
  - 支持批处理
  - 支持预执行
  
### [事务](https://docs.pingcap.com/zh/tidb/stable/transaction-overview)
- 事务流程  Snapshot Isolation 
  
  ![事务流程](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1634132247524.png)
  在事务提交的PreWrite阶段，当“锁检查”失败时：如果开启冲突重试，事务提交将会进行重试；如果未开启冲突重试，将会抛出写入冲突异常。
  可见，对于MySql，由于在写入操作时加上了排他锁，变相将并行事务从逻辑上串行化；而对于TiDB，属于乐观锁模型，在事务提交时才加锁，并使用事务开启时获取的“全局时间戳”作为“锁检查”的依据。
  所以，在业务面避免TiDB事务差异的本质在于避免锁冲突，即，当事务执行时，不产生别的事务时间戳（无其他事务并行）。处理方式为事务串行化。
  - 业务层加锁
    超时时间：为避免死锁，锁必须有超时时间；为避免锁超时导致事务并行，事务必须有超时时间，而且锁超时时间必须大于事务超时时间（时间差最好在秒级）。
    加锁时机：TiDB中“锁检查”的依据是事务开启时获取的“全局时间戳”，所以加锁时机必须在事务开启前。
  
  
## [ES](https://zhuanlan.zhihu.com/p/75990933)
```ES 在架构上主要分为集群、节点、索引、分片、段这五层结构。集群(cluster)包含了若干个 ES 节点，节点(node)角色分为 master 与 slave；
一个节点包含了若干个索引的部分数据，索引(index)可类比于关系型数据库中的表；一个索引包含若干个分片，ES 7.X 之前默认为5个分片，
ES 7.X之后默认为1个分片；一个分片(shard)是一个完整的 lucene Index , 其中包含了若干个段（segment）；段中则包含着 ES 最底层的数据结构如倒排索引、
docValue、stored field、cache 等 。架构图如下所示：
```
  
##存储解决方案
- Redis与MySQL双写一致性如何保证[双写一致性](https://www.cnblogs.com/rjzheng/p/9041659.html)
    
    从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。
    三种更新策略：
    
    1. 先更新数据库，再更新缓存(不建议)
        - 线程不安全，多线程更新数据，会导致缓存更新和数据库更新不一致
        - 业务：1.如果是写多读少，频繁更新，浪费。2.如果更新缓存需要计算，浪费性能。
    
   2. 先删除缓存，再更新数据库
        - 导致数据不一致 操作如下
           (1）请求A进行写操作，删除缓存
          （2）请求B查询发现缓存不存在
          （3）请求B去数据库查询得到旧值
          （4）请求B将旧值写入缓存
          （5）请求A将新值写入数据库
        - 解决：延时双删
           `
           （1）先淘汰缓存
           （2）再写数据库（这两步和原来一样）
           （3）休眠1秒（写数据的休眠时间>读业务的耗时xxx ms），再次淘汰缓存
          
           public void write(String key,Object data){
            		redis.delKey(key);
            	    db.updateData(data);
            	    Thread.sleep(1000);
            	    redis.delKey(key);
            	}
            	
           ` 
           - 同步删除：吞吐量降低，改成异步删除
           - mysql读写分离架构: 增加双删延时
           - 第二次删除,如果删除失败怎么办？: 先更库，再更缓存。
           
    3. 先更新数据库，再删除缓存
        - 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
        - 命中：应用程序从cache中取数据，取到后返回。
        - 更新：先把数据存到数据库中，成功后，再让缓存失效。
        - 这种情况不存在并发问题么？
        不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生
        （1）缓存刚好失效
        （2）请求A查询数据库，得一个旧值
        （3）请求B将新值写入数据库
        （4）请求B删除缓存
        （5）请求A将查到的旧值写入缓存
        ok，如果发生上述情况，确实是会发生脏数据。
        然而，发生这种情况的概率又有多少呢？
        发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。
        假设，有人非要抬杠，有强迫症，一定要解决怎么办？
        - 如何解决上述并发问题？
        首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。
        还有其他造成不一致的原因么？
        有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。
        - 如何解决缓存删除失败？
        提供一个保障的重试机制即可，这里给出两套方案。
    
    4. 重试机制
      删除失败的消息入队列，等待删除，配置好过期时间，重试次数等。
      - 业务实现：耦合高
        ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632655411407.png)
      - binlog实现：可以订阅binlog，但是结构变了会有影响，依赖于结构。
        ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1632655397729.png)
    
    
    

## 资料
  [mysql](https://aobing.blog.csdn.net/article/details/109257302)

  [数据库知识点](https://aobing.blog.csdn.net/article/details/109063250)

  [索引](https://aobing.blog.csdn.net/article/details/108436939)

  [MySQL如何设计索引更高效](https://aobing.blog.csdn.net/article/details/112451981)

  [delete?](https://aobing.blog.csdn.net/article/details/109735448)

  [text](https://aobing.blog.csdn.net/article/details/109569211)

  [数据库调优](https://juejin.cn/post/6844904201437315079)

  [事务&MVCC](https://aobing.blog.csdn.net/article/details/106915564)

  [mysql安全](https://aobing.blog.csdn.net/article/details/110383085)

## 面试题
- [字节面试题mysql](https://www.cnblogs.com/xiyuan2016/p/14351552.html)
- mysql 大表DDL [大表DDL](https://blog.csdn.net/weixin_35275781/article/details/113266503)
    - 业务的痛点
      
      尤其是对大型表的 DDL 操作，具有操作时间久，对性能影响大，可能影响业务正常使用等问题。
    - copy 算法
    - inplace 算法
    - instant 算法
    
    - 执行过程中尽量不要有未执行完成的长事务。
  
## es
 [es](https://blog.csdn.net/spirit_8023/article/details/85251106)
 