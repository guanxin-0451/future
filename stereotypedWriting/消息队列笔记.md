## 消息队列

### 原理
#### 设计思想
  - 动机
    - 通用的**实时数据推送**平台
    - 高容量
    - 高吞吐量
    - 能处理大量积压
    - 分区， 分布式
    - 出现故障时保证容错性
  - 持久化
    - 文件系统
      - read-ahead 和 write-behind
        - read-ahead 是以大的 data block 为单位预先读取数据，而 write-behind 是将多个小型的逻辑写合并成一次大型的物理磁盘写入
      - 顺序访问磁盘比某些情况下随机内存访问还要快
  - 查询/索引
    - 简单的文件末尾读：
      - 持久化队列可以建立在简单的读取和向文件后追加两种操作之上，这和日志解决方案相同。  
        这种架构的优点在于所有的操作复杂度都是O(1)，而且读操作不会阻塞写操作，读操作之间也不会互相影响
    - 存储量大：  
      我们可以让消息保留相对较长的一段时间(比如一周)，而不是试图在被消费后立即删除。正如我们后面将要提到的，这给消费者带来了很大的灵活性。
  - 性能
    - 消息块： 合理将消息分组，网络请求将多个消息打包成一组。  
        Consumer 每次获取多个大型有序的消息块，并由服务端 依次将消息块一次加载到它的日志中。
    - 字节拷贝：使用 producer ，broker 和 consumer 都共享的标准化的二进制消息格式，这样数据块不用修改就能在他们之间传递。
 
#### 概念
  - 生产消费模型
  ![](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1656520016411.png?x-oss-process=image/auto-orient,1/interlace,1/quality,q_50/format,jpg)
  - topic   
    主题 对存储的流数据进行分类
  - broker  
    - 缓存代理，Kafka集群中的一台或多台服务器统称broker.
    - 写入
      `如果Broker是集群部署，有多副本机制，即消息不仅仅要写入当前Broker,还需要写入副本机中。
      那配置成至少写入两台机子后再给生产者响应。这样基本上就能保证存储的可靠了。一台挂了还有一台还在呢（假如怕两台都挂了..那就再多些）。`
  - producer 
    `生产者发送消息至Broker，需要处理Broker的响应，不论是同步还是异步发送消息，同步和异步回调都需要做好try-catch，妥善的处理响应，
    如果Broker返回写入失败等错误消息，需要重试发送。当多次发送失败需要作报警，日志记录等。
     这样就能保证在生产消息阶段消息不会丢失`
  - consumer 消费者
    - 处理后再ack（offset 偏移+1）
    - 需要多线程去做（先落库，再ack，再去处理）
    
  - group 订阅者
    - 一个topic重的每个partion只会被1个订阅者的一个consumer消费
  - message：  
    - 一个key
    - 一个value
    - 一个timestamp（时间戳） 
    - offset:  
      - 记录groupid的消费情况 
      - 记录在broker下（leader broker）
    - 一条消息只在1个broker下
  
#### 如何保证消息的有序性？
  - 全局有序
    - 只能由一个生产者往topic里发送消息，并且1个topic内只能有1个分区。消费者也是单线程消费的。
  - 部分有序
    - 消息通过特定的策略发往固定的队列中。
    - 每个队列对应一个单线程处理的消费者。
  - 指定partition
  - 多个分区 通过hash算法 放入指定的桶 消费的时候同一个桶内则是有序的

#### 如何保证消息不重复？
  - 问题
    - 发送端
      `消息至少得发到Broker上，那就得等Broker的响应，那么就可能存在Broker已经写入了，当时响应由于网络原因生产者没有收到，然后生产者又重发了一次，此时消息就重复了。`
    - 消费者
      `，假设我们消费者拿到消息消费了，业务逻辑已经走完了，事务提交了，此时需要更新Consumer offset了，然后这个消费者挂了，另一个消费者顶上，此时Consumer offset还没更新，于是又拿到刚才那条消息，业务又被执行了一遍。于是消息又重复了。`
  - 解决 
    - 消息落库 落库的时候校验是否消费过。
    
### 什么场景用？
  - 异步处理
    - 调用链路长、响应就慢了，并且相对于扣库存和下单，积分和短信没必要这么的 "及时"。因此只需要在下单结束那个流程，
    扔个消息到消息队列中就可以直接返回响应了。而且积分服务和短信服务可以并行的消费这条消息。
  - 服务解耦
    - 消息谁需要谁去消费
  - 流量控制
    - 削峰
    - 填谷
### [kafka为什么快](https://mp.weixin.qq.com/s?__biz=MzAwNDA2OTM1Ng==&mid=2453145438&idx=2&sn=b0a5a87fc31aed4f3a48df2d65af8ffe&scene=21#wechat_redirect)
- read-ahead 和 write-behind
  - read-ahead 是以大的 data block 为单位预先读取数据，而 write-behind 是将多个小型的逻辑写合并成一次大型的物理磁盘写入
- 顺序访问磁盘比某些情况下随机内存访问还要快
- 查询/索引
- 简单的文件末尾读：
  - 持久化队列可以建立在简单的读取和向文件后追加两种操作之上，这和日志解决方案相同。  
    这种架构的优点在于所有的操作复杂度都是O(1)，而且读操作不会阻塞写操作，读操作之间也不会互相影响
- 消息块： 合理将消息分组，网络请求将多个消息打包成一组。  
        Consumer 每次获取多个大型有序的消息块，并由服务端 依次将消息块一次加载到它的日志中。
- 字节拷贝：使用 producer ，broker 和 consumer 都共享的标准化的二进制消息格式，这样数据块不用修改就能在他们之间传递。
 
### 
### 能满足什么能力？
### 内部流程？
### 外部使用流程？

### [官方文档](https://kafka.apachecn.org/documentation.html#design)
