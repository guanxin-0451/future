## Redis
[TOC]

redis和mem cache?  
一致性哈希？
### 数据结构
- 应用层数据结构
  1. string
  2. hash
  3. List
  4. Set
  5. SortedSet(zset)
   
- 底层数据结构
    1. 简单动态字符串 SDS
    
       ```
       struct sdshdr {
            //记录buf数组中已使用字节的数量
            //等于SDS所保存字符串的长度
            int len;
            //记录buf数组中未使用字节的数量
            int free;
            //字节数组，用于保存字符串
            char buf[];
        };
       ```
        1. 计算len o（1）
        2. 可以检查空间，选择**是否可以扩容**来修改字符串，杜绝缓冲区问题
        3. 解除了字符串长度和数组长度的关联
        4. 预分配空间&惰性空间释放
        预分配：小于1mb的 分配len=free的空间 大于1mb的 分配free  = 1mb
        5. 二进制安全
    
    2. 链表
      1. 双向链表
         - 链表被广泛用于实现Redis的各种功能，比如列表键、发布与订阅、慢查询、监视器等。
         - 每个链表节点由一个listNode结构来表示，每个节点都有一个指向前置节点和后置节点的指针，所以Redis的链表实现是双端链表。
         - 每个链表使用一个list结构来表示，这个结构带有表头节点指针、表尾节点指针，以及链表长度等信息。
         - 因为链表表头节点的前置节点和表尾节点的后置节点都指向NULL，所以Redis的链表实现是无环链表。
         - 通过为链表设置不同的类型特定函数，Redis的链表可以用于保存各种不同类型的值。
    
    3. 字典
        - [美团针对Redis Rehash机制的探索和实践](https://tech.meituan.com/2018/07/27/redis-rehash-practice-optimization.html)
        - murmurhash hash算法 有较好的随机性
          
        - 负载因子
            1. 负载因子是1.0：
            `意味着，只有当数组的8个值（这个图表示了8个）全部填充了，才会发生扩容。这就带来了很大的问题，因为Hash冲突时避免不了的。当负载因子是1.0的时候，意味着会出现大量的Hash的冲突，底层的红黑树变得异常复杂。对于查询效率极其不利。这种情况就是牺牲了时间来保证空间的利用率。
            因此一句话总结就是负载因子过大，虽然空间利用率上去了，但是时间效率降低了。`
          
            2. 负载因子是0.5
            `负载因子是0.5的时候，这也就意味着，当数组中的元素达到了一半就开始扩容，既然填充的元素少了，Hash冲突也会减少，那么底层的链表长度或者是红黑树的高度就会降低。查询效率就会增加。
            但是，这时候空间利用率就会大大的降低，原本存储1M的数据，现在就意味着需要2M的空间。
            一句话总结就是负载因子太小，虽然时间效率提升了，但是空间利用率降低了。`
            
            3. 负载因子0.75
            `经过前面的分析，基本上为什么是0.75的答案也就出来了，这是时间和空间的权衡`
        - 解决冲突：链地址法
        - rehash
          1. 由负载因子（已保存节点数量）/ 哈希表大小决定是否在由bgsave的时候来扩展/收缩
          2. 渐进式rehash  
            `渐进式rehash执行期间，新增的会保存在ht[1]上，删除，查找，更新会在两个哈希表上进行` 
          
    4. 跳跃表  sortedset  
    `Redis只在两个地方用到了跳跃表，一个是实现**有序集合键**，另一个是在集群节点中用作内部数据结构
    Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成，其中zskiplist用于保存跳跃表信息（比如表头节点、表尾节点、长度），
    而zskiplistNode则用于表示跳跃表节点。❑每个跳跃表节点的层高都是1至32之间的随机数。❑在同一个跳跃表中，多个节点可以包含相同的分值，
    但每个节点的成员对象必须是唯一的。❑跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。`  
    [实现](https://www.jianshu.com/p/fef9817cc943)
    
    5. 整数集合  
    可调整的集合元素类型  
    升级  
    1）根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。2）将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素放置到正确的位上，而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。3）将新元素添加到底层数组里面。  
    降级  
    整数集合不支持降级  
    二分查找实现查找/去重
    
    6. 压缩列表（ziplist）  
    是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现
    压缩列表是单向的，需要记录首尾，可以从首位遍历  
    `hash时什么情况才用ziplist  
     同时满足以下条件：
     1. 哈希对象保存的所有键值的字符串长度小于64字节；
     2. 哈希对象保存的键值对数量小于512个；`
     
    7. quickList  
        `在 Redis3.2 版本之后，Redis 集合采用了 QuickList 作为 List 的底层实现，QuickList 其实就是结合了 ZipList 和 LinkedList 的优点设计出来的。
         
         各部分作用说明：
         
         每个 listNode 存储一个指向 ZipList 的指针，ZipList 用来真正存储元素的数据。
         
         ZipList 中存储的元素数据总大小超过 8kb（默认大小，通过 list-max-ziplist-size 参数可以进行配置）的时候，就会重新创建出来一个 ListNode 和 ZipList，然后将其通过指针关联起来。`
### 持久化
  - RDB  
    - 优先载入aof持久化的文件  
    - save是同步的，会阻塞其他客户端的请求
    - bgsave: redis 主进程 会fork一个子进程来数据同步。
    - bgsave同时只能执行一个，防止竞争  
    - bgsave和bgrewaitaof只能执行一个，性能考虑，防止大量io  
    - redis轮询:  
    Redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，
    它的其中一项工作就是检查save选项所设置的保存条件是否已经满足，如果满足的话，就执行BGSAVE命令。  
    - dirty和lastsave  
      dirty: 修改db次数  
      lastsave: 上次执行时间
    - Q 执行bgsave时，数据持续进入，怎么保存的？  
    copy-on-write ：fork的子进程通过只读方式共享内存段，写时单独开辟空间
    `Copy On Write技术实现原理：
     fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，
     于是触发页异常中断（page-fault），陷入kernel的一个中断例程。
     中断例程中，kernel就会把触发的异常的页复制一份，**于是父子进程各自持有独立的一份。**
     Copy On Write技术好处是什么？
     COW技术可减少分配和复制大量资源时带来的瞬间延时。
     COW技术可减少不必要的资源分配。比如fork进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。
     Copy On Write技术缺点是什么？
     如果在fork()之后，父子进程都还需要继续进行写操作，那么会产生大量的分页错误(页异常中断page-fault)，这样就得不偿失。`
    - Q [RDB 为什么fork进程而不是线程](https://zhuanlan.zhihu.com/p/114547256)
      `主线程写，没办法确定某一时间点的数据快照`
    - RDB的几个优点
      - 与AOF方式相比，通过rdb文件恢复数据比较快。
      - rdb文件非常紧凑，适合于数据备份。
      - 通过RDB进行数据备，由于使用子进程生成，所以对Redis服务器性能影响较小。
    - RDB的几个缺点
      - 如果服务器宕机的话，采用RDB的方式会造成某个时段内数据的丢失，比如我们设置10分钟同步一次或5分钟达到1000次写入就同步一次，那么如果还没达到触发条件服务器就死机了，那么这个时间段的数据会丢失。
      - 使用save命令会造成服务器阻塞，直接数据同步完成才能接收后续请求。
      - 使用bgsave命令在forks子进程时，如果数据量太大，forks的过程也会发生阻塞，另外，forks子进程会耗费内存。
  
  - AOF 持久化
    - 原理：  
      AOF持久化方式会记录客户端对服务器的每一次写操作命令，并将这些写操作以Redis协议追加保存到以后缀为aof文件末尾，在Redis服务器重启时，会加载并运行aof文件的命令，以达到恢复数据的目的。
    - 通过伪客户端来执行aof文件内命令  
      aof rewrite 。 BGREWRITEAOF  
      重写时主进程不阻塞，持续进入数据：为了解决这种数据不一致问题（不阻塞，导致主进程和子进程不一致），
      Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，
      当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区
      
      aof新旧文件替换
    - 优缺点
      - 优点：  
      数据更完整，秒级数据丢失(取决于设置fsync策略)。
      兼容性较高，由于是基于redis通讯协议而形成的命令追加方式，无论何种版本的redis都兼容，再者aof文件是明文的，可阅读性较好。
      - 缺点：  
      数据文件体积较大,即使有重写机制，但是在相同的数据集情况下，AOF文件通常比RDB文件大。
      相对RDB方式，AOF速度慢于RDB，并且在数据量大时候，恢复速度AOF速度也是慢于RDB。
      由于频繁地将命令同步到文件中，AOF持久化对性能的影响相对RDB较大，但是对于我们来说是可以接受的。
      混合持久化

  - 混合模式
    - bgrewriteaof  
    fork出的子进程先将共享的内存副本全量的以RDB方式写入aof文件，然后在将重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。简单的说：新的AOF文件前半段是RDB格式的全量数据后半段
### 数据库
   ![重点](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633539034951.png)
   
### 事务
  - multi: 开启事务
  - exec： 类似commit，执行时按顺序执行队列内的操作
  - watch: 乐观锁，执行时check一下队列里的键这期间是否有操作。
  - 事务队列
  - 不支持回滚 
  - 原子性： 入队时如果失败，就全失败，但是执行过程中某一条失败，并不会回滚。
  - 一致性: 不影响。
  - 隔离性： 多个事务并发执行，不会互相影响： 单线程。串行化执行，没有影响。
  - 持久性:  事务队列本身没有持久性。

### 内存模型 
   ```Redis的内存占用主要可以划分为以下几个部分：
      
      1、数据
      作为数据库，数据是最主要的部分；这部分占用的内存会统计在used_memory中。
      Redis使用键值对存储数据，其中的值（对象）包括5种类型，即字符串、哈希、列表、集合、有序集合。这5种类型是Redis对外提供的，实际上，在Redis内部，
      每种类型可能有2种或更多的内部编码实现；此外，Redis在存储对象时，并不是直接将数据扔进内存，而是会对对象进行各种包装：如redisObject、SDS等；

      2、进程本身运行需要的内存
      Redis主进程本身运行肯定需要占用内存，如代码、常量池等等；这部分内存大约几兆，在大多数生产环境中与Redis数据占用的内存相比可以忽略。
      这部分内存不是由jemalloc分配，因此不会统计在used_memory中。
      补充说明：除了主进程外，Redis创建的子进程运行也会占用内存，如Redis执行AOF、RDB重写时创建的子进程。当然，这部分内存不属于Redis进程，
      也不会统计在used_memory和used_memory_rss中。
            
      3、缓冲内存
      缓冲内存包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等；其中，客户端缓冲存储客户端连接的输入输出缓冲；复制积压缓冲用于部分复制功能；
      AOF缓冲区用于在进行AOF重写时，保存最近的写入命令。在了解相应功能之前，不需要知道这些缓冲的细节；
      这部分内存由jemalloc(内存分配器)分配，因此会统计在used_memory中。

      4、内存碎片
      内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据的更改频繁，而且数据之间的大小相差很大，
      可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，这就形成了内存碎片。内存碎片不会统计在used_memory中。
      内存碎片的产生与对数据进行的操作、数据的特点等都有关；此外，与使用的内存分配器也有关系：
      如果内存分配器设计合理，可以尽可能的减少内存碎片的产生。后面将要说到的jemalloc便在控制内存碎片方面做的很好。
   ```
### 集群
  - 主从复制
    - 特点：
      - 数据冗余
      - 故障恢复 可以切从节点为主节点
      - 负载均衡： 读写分离 写主读从
      - 高可用:
    - PSYNC
      - 完整重同步： 创建并发送rdb文件&发送缓冲区的写命令
      - 命令传播： 写命令持续发送给从服务器
      - 部分重同步： 断线后重新同步
      - 根据操作的偏移量，来确认是否断开链接，丢失部分操作，向主节点发送psync命令同步，检查偏移量。
    
  - 哨兵
    - sentinel是个特殊的redis服务，不支持redis的基本功能，支持复制，发布订阅等。
    - sentinel 进程
      - 监控集群中master主服务器工作的状态  
      - 提醒
      - 自动故障救援
      - 通过命令链接发送ping 给主，从， 其他sentinel发送
      - 通过订阅 订阅主服务器的__sentinel__: hello频道。
    - 主观下线和客观下线
      - 主观下线：某个sentinel发现了master实例长时间无效回复。
      - 客观下线： sentinel开始询问其他的sentinel，看看是否有超过x（通常是半数）认为master下线。
    - 选举领头sentinel：
      - 给其他sentinel发送做主的命令，超半数同意即通过。
      - raft：[raft选举](http://blog.itpub.net/31556438/viewspace-2637112/)
        
    - 领头 sentinel 进行选主服务器：
      - 根据断连时间筛掉一批
      - 根据复制偏移量选一个最大的（有最新的数据）
    - 将旧的从切换主到新的主
    - 如果旧的主上线，作为从服务器
    
  - cluster
    - 解决问题：  
      单写服务 可接纳吞吐量差，需要多写服务。  
      大量数据 bgsave rdb文件大，从节点接收慢，延迟高
    - 主要组成
      - 数据分片  
        使用hash槽位 16384个槽位2^14
      - 主从复制模型
      - 故障转移
    - 结构：多组 主从 
    - 支持槽位迁移 [槽](https://www.cnblogs.com/sulishihupan/p/14538864.html)
      重新分片 
      概念：将任意数量已经指派给某个节点的槽，改为指派给另一个节点，其中，槽对应的所有键值对都需要迁移。
      特点：1、重新分片是可以在线进行的，集群无需下线  
       2、 重新分片过程中，源节点和目标节点都可以继续处理命令请求（因为重新分片操作是键值对不断的迁移？）
    
  - [codis](https://www.cnblogs.com/pingyeaa/p/11294773.html)
  
  
### 发布订阅

### 常见问题
#### 一致性哈希[一致性哈希](https://www.zsythink.net/archives/1182)
    - 解决问题：hash扩容 缩容 扩容/缩容时 所有的缓存的位置都可能发生改变
    - 算法:  
      1. 对2^32取模，形成一个0 - 2^32-1的环  
      2. 先将需要分的块hash到环上  
      3. 将值hash到环上
      4. 值右侧的第一个hash块就是所属的块
      ![一致性哈希](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633449349948.png)
      5. 摘除某个块时，只会对他本身和他右侧的块影响，其他的块不受影响
      6. hash环倾斜： 增加虚拟节点对应实际节点
      ![一致性哈希-解决倾斜](https://cynthia-oss.oss-cn-beijing.aliyuncs.com/1633449622001.png)
      7. 开放寻址法解决冲突即可

#### redis 缓存穿透，缓存击穿，缓存雪崩，热点数据集中失效
  - 缓存穿透：  
  在缓存层和数据库层，都没有找到数据。解决方案一：把空对象缓存起来，并设置合理的过期时间。解决方案二：使用布隆过滤器
  - 缓存击穿：  
  
  缓存中的数据在某个时刻批量过期，导致大部分的请求都会直接落在数据库上。解决方案一：针对不同类型的数据，设置不同的过期时间。解决方案二：使用分布式锁。
  - 缓存雪崩：  
  缓存在某一时刻集中失效，或者缓存系统出现故障，所有的并发流量会直接到达数据库。解决方案一：保证redis的高可用，使用集群部署。解决方案二：限流降级
  - 热点数据集中失效 ：  
  类似于缓存击穿。热点数据同时失效，造成都去查数据库。解决方案：利用集群部署，保证redis的高可用。

#### redis 为什么那么快？
   - 采用多路复用IO阻塞机制  
     多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，
     当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），
     并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。  
     这里的多路指的是多个请求，复用指的是复用同一个线程，
     采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），
     且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，
     主要由以上几点造就了 Redis 具有很高的吞吐量
     
   - 数据结构简单，操作节省时间
   - 运行在内存中 
   - 单线程,避免多线程切换
   - 什么时候用多线程？：什么时候用多线程的方案呢？  
    【IOPS（Input/Output Operations Per Second）是一个用于计算机存储设备（如硬盘（HDD）、固态硬盘（SSD）或存储区域网络（SAN））性能测试的量测方式】  
    【吞吐量是指对网络、设备、端口、虚电路或其他设施，单位时间内成功地传送数据的数量（以比特、字节、分组等测量）】  
     答案是：下层的存储等慢速的情况。比如磁盘  
     原子性： 在单线程中,能够在单条指令中完成的操作都可以认为是“原子操作”

#### redis 什么情况下会出现性能问题，有什么处理办法？
   - 支持10w+QPS
   - master写内存快照  
       save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。
   - Master AOF持久化  
     如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。
   - Master调用BGREWRITEAOF重写AOF文件  
     AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。
   - Redis主从复制的性能问题  
     为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内
   - Redis的瓶颈：
     ```1.机器内存大小，因为redis的数据放在内存里，所以存放数据量的多少取决于内存的多少
        
        2.网络带宽
        
        Redis客户端执行一条命令分为如下四个过程：
        
        1）发送命令
        
        2）命令排队
        
        3）命令执行
        
        4）返回结果
        
        其中1）+4）称为Round Trip Time（RTT，往返时间）。
        
        Redis的客户端和服务端可能部署在不同的机器上。例如客户端在北京，Redis服务端在上海，两地直线距离约为1300公里，
     那么1次RTT时间=1300×2/（300000×2/3）=13毫秒（光在真空中传输速度为每秒30万公里，这里假设光纤为光速的2/3），
     那么客户端在1秒内大约只能执行80次左右的命令，这个和Redis的高并发高吞吐特性背道而驰
        
        所以要么就在全国各地都有自己的Redis服务器，然后就近访问，要么就使用Pipeline
        
        Pipeline（流水线）机制能改善上面这类问题，它能将一组Redis命令进行组装，通过一次RTT传输给Redis，
     再将这组Redis命令的执行结果按顺序192返回给客户端，下图为没有使用Pipeline执行了n条命令，整个过程需要n次RTT```
   - 超高qps的场景
     ```
     Redis服务支持5000万的QPS，有什么好的思路？
     其中写请求有2000万左右；需要持久化，高可用；
     
     redis cluster为例，假设每个节点跑8W QPS，那么也需要 5000/8 = 600+的节点，而Gossip在超过百级别节点的时候成本就越来越高，表现也越来越差了，
     所以用redis cluster来解这个问题不大靠谱，不靠谱的主要原因是Gossip的通信机制。
     

     对于几个大厂来说，阿里云ApsaraDB for Redis/ApsaraCache用的是自研的集群方案（架构类似Codis），RedisLabs也是这个架构，
     AWS用的是开源的Redis Cluster，其他大厂就不清楚了。proxy+redis-server的架构可以做到线性的扩容，不用担心节点间的通讯压力，因为proxy做了分片，
     虽然也需要全局的Config Server/Zookeeper来维护数据分片信息，但是总体而言通信成本几乎为0，所以这种架构撑5000W QPS理论上是没有问题的。
     这种架构还有一个优点就是可以把proxy当成一个中间件，在这个中间件上你可以做任何事情，比如可以把集群和主从的兼容性做到几乎一致、可以做无缝扩缩容、
     安全策略等等，redis cluster因为缺少了这么一个中间层就很难做这类事情（现在也有项目给redis cluster做一层proxy），当然因为带了proxy，
     带宽和CPU基本也是double的，对资源的消耗会大很多。回到5000W这个问题上，理论上没问题不代表实际没问题，在几百个节点的集群中，
     由于节点数变多，fail的几率也大大变高；数据倾斜的问题也依然存在（访问热点导致的单个分片节点跑满，比如秒杀）；
     而且由于redis跑满时70-80%的cpu会消耗在内核网络栈上，所以当一个机器的CPU跑满时，cpu system和softirq会居高不下，
     对主机的稳定性是个巨大的挑战；另外对机房各个层次的交换机也会有巨大的挑战；总而言之，服务的SLA是很难得到满足的，
     为了保证SLA，可能需要上百台机器来部署几百个分片以分担5000W的压力，这个成本也不是一般小厂能承担的。
     而且节点数多的时候，对一些跨机指令是不友好的，比如mget，当节点数变多的时候会存在mget hole的问题，
     延迟与单节点相比会是原来的1/2次方倍，比如9个节点，mget的延迟就是原来的3倍，100个节点，延迟就是原来的10倍，懂概率的同学可以自己算一下。
     那到底如何彻底解决5000W这个问题呢，这里还是需要引入新技术的，比如智能网卡、用户态tcp/ip协议栈、多线程redis（减少分片数量，兼容性依然100%）
     ，纯用户态协议栈可以做到单机600W QPS（64 core）左右，用intel iWARP这个值可能能达到1500W QPS左右（把7层网络栈都offload到网卡），
     这样3-4台baremetal机器就能达到你说的要求；上层交换机也要用最新的机房建设标准，而且redis源码本身也要做很多的适配和重构；
     产品形态也要做相应改进，比如我们为了支持热key就做了读写分离这种产品形态。
     ```


#### 热点问题
  - 热key
    - 用户消费的数据远大于生产的数据（热卖商品、热点新闻、热点评论、明星直播）。
    - 请求分片集中，超过单 Server 的性能极限
    - 解决：
      - 服务端缓存  
        脏读问题  
        缓存丢失问题
      - memcache + redis
      
  - 大key  
  大key的风险：  
  读写大key会导致超时严重，甚至阻塞服务。  
  如果删除大key，DEL命令可能阻塞Redis进程数十秒，使得其他请求阻塞，对应用程序和Redis集群可用性造成严重的影响。
  建议每个key不要超过M级别。  
  解决： hash拆分 拆分到不同的桶里 用一致性哈希来扩桶和缩桶
  
#### redis 分布式锁
  - setnx
  - 资源未释放，锁自动过期，怎么办？
    java有redisson 检测锁的过期时间 守护线程，锁自动续期
  - 锁被别的线程/进程释放怎么办？  
    加一个唯一标识 setnx的时候  
    lua脚本来实现 get锁+del锁的原子操作
  - 切换主从的失效问题  
    解决：redlock  
    不再需要部署从库和哨兵实例，只部署主库  
    但主库要部署多个，官方推荐至少 5 个实例  
    利用 .Quorum机制 3个实例存在锁就算成功
  - 无法完全解决一致性
    
####  redis 和 memcache 的区别
     memcache仅支持简单的key-value数据结构，redis支持字符串、哈希、链表、set集合，有序set集合
     redis不是所有的数据都存储在内存，会将一些很久没用的value交换到磁盘
     redis采用的单核，memcache可以采用多核，在存储小数据的时候，redis性能更好，而在大数据的时候，memcache性能更好
     redis集群可以采用一主多从，一主一从。memcache集群只能采用一主多从
     redis支持数据恢复。memcache不支持
     
#### redis cluster为什么选择2^14个槽位？
  ```
The reason is:

Normal heartbeat packets carry the full configuration of a node, 
that can be replaced in an idempotent way with the old in order to update an old config. 
This means they contain the slots configuration for a node, in raw form, 
that uses 2k of space with16k slots, but would use a prohibitive 8k of space using 65k slots.
At the same time it is unlikely that Redis Cluster would scale to more than 1000 mater nodes because of other design tradeoffs.
So 16k was in the right range to ensure enough slots per master with a max of 1000 maters,
 but a small enough number to propagate the slot configuration as a raw bitmap easily. 
Note that in small clusters the bitmap would be hard to compress because when N is small the bitmap would have slots/N 
bits set that is a large percentage of bits set.
  ```

#### 过期
过期时间 移除过期时间 PERSIST
expires字典 维护所有键的过期时间 。  键是指针
删除策略：定时，定期，惰性
`redis允许用户通过配置maxmemory-policy参数，指定redis在内存不足时的解决策略。
 　　1.volatile-lru 使用LRU算法删除一个键(只针对设置了过期时间的key
 　　2.allkeys-lru 使用LRU算法删除一个键
 　　3.volatile-lfu 使用LFU算法删除一个键(只针对设置了过期时间的键)
 　　4.allkeys-lfu 使用LFU算法删除一个键
 　　5.volatile-random 随机删除一个键(只针对设置了过期时间的键)
 　　6.allkeys-random 随机删除一个键
 　　7.volatile-ttl 删除最早过期的一个键
 　　8.noeviction 不删除键，返回错误信息(redis默认选项)
 `
#### 布隆过滤器
  `当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在`
  - 通过k个散列函数映射成1个位数组的k个点，置为1，检索时，如果有任何1个0 肯定不存在
  - Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。
  - 删除困难 不能直接置成0
  - 适用场景
    - 短链接
    - 缓存击穿
    
### 资料&参考
  [持久化](https://www.cnblogs.com/javazhiyin/p/11425060.html)
  [布隆过滤器](https://juejin.cn/post/6844903982209449991)
  [面试题](https://blog.csdn.net/w139074301/article/details/112550908)